{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2eb9cc28",
      "metadata": {
        "id": "2eb9cc28"
      },
      "source": [
        "# STA410 Coding Challenge II (10 points)\n",
        "\n",
        "Welcome.\n",
        "\n",
        "- If you experience technical issues while working on this coding challenge, send a message to sta410@utoronto.ca.\n",
        "\n",
        "- Any live messages that need to be communicated to the class in real-time during the coding challenge will be posted on [piazza](https://piazza.com/utoronto.ca/winter2023/sta410).\n",
        "\n",
        "- ***You may add cells for scratch work***, but if required answers are not submitted through the provided cells where the answers are requested your answers will not be graded.\n",
        "\n",
        "- ***If you accidentally delete a required cell***, try \"Edit > Undo Delete Cells\" in the notebook editor; otherwise, redownload the notebook (so it has the correct required cells ids) and repopulate it with your answers (assuming you don't overwrite them).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Rules\n",
        "\n",
        "0. **This is an individual assignment.** You are not permitted to engage in any form of active or passive collusion or collaboration with other human beings while working on this challenge.  ***You may NOT access chat or communication applications during the coding challenge.***\n",
        "\n",
        "\n",
        "1. You are welcome and encouraged to adapt code you find available online into your notebook; however, if you do so you must provide a link to the utilized resource. ***Failure to list such references may result in a loss of points.***\n",
        "\n",
        "\n",
        "2. **Do not delete or replace cells**: this erases `cell ids` upon which automated code tests are based.\n",
        "\n",
        "  > ***If you are working in any environment other than*** [UofT JupyterLab](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master&urlpath=/lab/tree/sta410hw0), [UofT JupyterHub](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master), or [Google Colab](https://colab.research.google.com/github/pointOfive/sta410hw0/blob/master/sta410hw0.ipynb), your system must meet the following versioning requirements \n",
        "   >\n",
        "   >   - [notebook format >=4.5](https://github.com/jupyterlab/jupyterlab/issues/9729) \n",
        "   >   - jupyter [notebook](https://jupyter.org/install#jupyter-notebook) version [>=6.2](https://jupyter-notebook.readthedocs.io/en/stable/) for \"classic\" notebooks served by [jupyterhub](https://jupyterhub.readthedocs.io/en/stable/quickstart.html)\n",
        "   >   - [jupyterlab](https://jupyter.org/install) version [>=3.0.13](https://github.com/jupyterlab/jupyterlab/releases/tag/v3.0.13) for \"jupyterlab\" notebooks  \n",
        "   >    \n",
        "   > otherwise `cell ids` will not be supported and you will not get any credit for your submitted homework.  \n",
        "      \n",
        "      \n",
        "3. **No cells may have any runtime errors** because this causes subsequent automated code tests to fail and you will not get marks for tests which fail because of previous runtime errors. \n",
        "\n",
        "  - Run time errors include, e.g., unassigned variables, mismatched parentheses, and any code which does not work when the notebook cells are sequentially run, even if it was provided for you as part of the starter code. ***It is best to restart and re-run the cells in your notebook to ensure there are no runtime errors before submitting your work.***\n",
        "    \n",
        "  - The `try`-`except` block syntax catches runtime errors and transforms them into `exceptions` which will not cause subsequent automated code tests to fail.  \n",
        "\n",
        "\n",
        "4. **No jupyter shortcut commands** such as `! pwd` or `%%timeit` may be included in the final submission as they will cause subsequent automated code tests to fail.\n",
        "\n",
        "  - ***Comment out ALL jupyter shortcut commands***, e.g., `# ! pwd` or `# %%timeit` in submitted notebooks.\n",
        "\n",
        "5. **Python library imports are limited** to only libraries imported in the starter code and the [standard python modules](https://docs.python.org/3/py-modindex.html). Importing additional libraries will cause subsequent automated code tests to fail.\n",
        "\n",
        "  > Unless a problem instructs differently, you may use any functions available from the libraries imported in the starter code; otherwise, you are expected to create your own Python functionality based on the Python stdlib (standard libary, i.e., base Python and standard Python modules)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "8adab7cb",
      "metadata": {
        "deletable": false,
        "id": "8adab7cb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d135f5",
      "metadata": {
        "id": "55d135f5"
      },
      "source": [
        "# Problem 1 (5 points)\n",
        "\n",
        "This problem will explore ***Iteratively Reweighted Least Squares IRLS*** in the context of a ***log linear model*** with a ***Poisson*** distribution. \n",
        "\n",
        "For a ***log-linear model*** $\\lambda_i = E[y_i|x_i, \\beta] = Var[y_i|x_i, \\beta] = \\exp(x^T_i\\beta)$ with a ***Poisson*** distribution\n",
        "\n",
        "$$f\\left(y_i|\\lambda_i= \\exp(x^T_i\\beta)\\right) = \\frac{\\exp(-\\lambda_i)\\lambda^y_i}{y_i!} = \\frac{\\exp(-\\exp(x_i^T\\beta))\\exp(x_i^T\\beta)^{y_i}}{y_i!}$$\n",
        "\n",
        "For this ***generalized linear model***\n",
        "- the ***link function*** $\\phi$ is $\\phi(\\lambda_i) = \\ln \\lambda_i = x_i^T\\beta$ so $\\lambda_i = E[y_i|x_i, \\beta] = Var[y_i|x_i, \\beta] = \\exp(x_i^T\\beta)$\n",
        "    - and for the $\\phi(\\cdot) = \\ln(\\cdot)$ ***link function***, $\\phi'(\\cdot) = (\\cdot)^{-1}$ \n",
        "- the ***log likelihood*** ignoring the $(y_i!)$ ***normalizing constant*** is $$\\ln f(y_i|\\lambda_i) = -\\lambda_i + y_i\\ln\\lambda_i = -\\exp(x_i^T\\beta) + y_i (x_i^T\\beta)$$ \n",
        "- the ***score function*** is $$S(\\beta) = \\sum_{i=1}^n \\nabla_\\beta \\ln f(y_i|\\lambda_i) = \\sum_{i=1}^n  -\\exp(x_i^T\\beta)x_i + y_i x_i = \\sum_{i=1}^n (y_i-\\lambda_i)x_i = X^T(y-\\lambda)$$ \n",
        "- and the ***expected Fisher Information*** is \n",
        "\n",
        "  \\begin{align*}\n",
        "  \\mathcal I(\\beta) = -E\\left[\\sum_{i=1}^n H \\ln f(y_i|\\lambda_i)\\right] & = {} -E\\left[\\sum_{i=1}^n J \\nabla_\\beta \\ln f(y_i|\\lambda_i)\\right] \\\\\n",
        "  & = {} E\\left[\\sum_{i=1}^n (\\nabla_\\beta \\ln f(y_i|\\lambda_i))(\\nabla_\\beta \\ln f(y_i|\\lambda_i))^T\\right] \\\\\n",
        "  & = {} \\sum_{i=1}^n E\\left[(y_i-\\lambda_i)^2\\right]x_ix_i^T = \\sum_{i=1}^n  \\lambda_ix_ix_i^T  = X^TD(\\lambda)X \\quad D_{ii}(\\lambda)=\\lambda_i \\quad D_{\\underset{\\neq}{ij}}(\\lambda)=0\n",
        "  \\end{align*}\n",
        "\n",
        "\n",
        "***Newton's method*** and ***Fisher scoring*** for this specification are thus, respectively\n",
        "\n",
        "\\begin{align*}\n",
        "\\beta^{(t+1)} & = {} \\beta^{(t)} - [H f(y|\\lambda^{(t)})]^{-1} S(\\beta^{(t)})\\\\\n",
        "\\beta^{(t+1)} & = {} \\beta^{(t)} + \\mathcal I(\\beta)^{-1} S(\\beta^{(t)})\\\\\n",
        "& = {} \\beta^{(t)} + (X^TD(\\lambda^{(t)})X)^{-1} S(\\beta^{(t)})\\\\\n",
        "& = {} (X^TD(\\lambda^{(t)})X)^{-1} \\left(X^TD(\\lambda^{(t)})X\\beta^{(t)} + S(\\beta^{(t)}) \\right)\\\\\n",
        "& = {} (X^TD(\\lambda^{(t)})X)^{-1} \\Bigg(X^TD(\\lambda^{(t)})X\\beta^{(t)} + X^TD(\\lambda^{(t)})[D(\\lambda^{(t)})]^{-1} \\left(y-\\lambda^{(t)}\\right) \\Bigg)\\\\\n",
        "& = {} (X^TD(\\lambda^{(t)})X)^{-1} X^TD(\\lambda^{(t)}) \\Bigg(X\\beta^{(t)} + \\overbrace{\\left[\\frac{y-\\lambda^{(t)}}{\\lambda^{(t)}} \\right]}^{\\text{element-wise}} \\Bigg)\\\\\n",
        "\\end{align*}\n",
        "\n",
        "which is the solution of the ***weighted least squares regression*** of $\\tilde y^{(t)} = \\left(X\\beta^{(t)} + \\frac{y-\\lambda^{(t)}}{\\lambda^{(t)}}\\right)$ against $X$ with ***weights*** $D(\\lambda^{(t)})$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b52612f",
      "metadata": {
        "id": "6b52612f"
      },
      "source": [
        "## Problem 1 Questions 0-1 (1 point)\n",
        "\n",
        "0. (0.5 points) Which of the following are equal to $D(\\lambda^{(t)})$?\n",
        "\n",
        "    1. $\\hat y^{(t)}$ \n",
        "    2. $E[y | x_i,\\lambda^{(k)}]$\n",
        "    3. $Var[y | x_i,\\lambda^{(k)}]$\n",
        "    4. All of the above  \n",
        "    \n",
        "\n",
        "1. (0.5 points) Which of the following are equal to $\\tilde y^{(t)}$? \n",
        "\n",
        "    1. $\\hat y^{(t)} + \\frac{y - E[y | x_i,\\lambda^{(t)}]}{\\hat y^{(t)}}$ \n",
        "    2. $\\hat y^{(t)} + \\frac{y - E[y | x_i,\\lambda^{(t)}]}{SD[y | x_i,\\lambda^{(t)}]}$ \n",
        "    3. $\\ln \\hat y^{(t)} + \\frac{y - \\hat  y^{(t)}}{Var[y | x_i,\\lambda^{(t)}]}$\n",
        "    4. $\\ln \\hat y^{(t)} + \\frac{y - E[y | x_i,\\lambda^{(t)}]}{SD[y | x_i,\\lambda^{(t)}]}$ \n",
        "    \n",
        "    \n",
        "***Hint:*** The $\\hat y^{(t)}$ is the prediction of $y$ at time $t$. What is that?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "059f940e",
      "metadata": {
        "id": "059f940e"
      },
      "outputs": [],
      "source": [
        "# 0.5 points each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
        "p1q0 = \"D\" \n",
        "p1q1 = \"A\"\n",
        "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
        "\n",
        "# This cell will produce a runtime error until the `p1q0` and `p1q1` variables are assigned values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bc4e2e7",
      "metadata": {
        "id": "6bc4e2e7"
      },
      "source": [
        "## Problem 0 Question 2-3 (1 point)\n",
        "\n",
        "2. (0.5 points) For the design matrix `X` below, and $\\beta_j = \\frac{10-j}{10}$ with intercept $\\beta_0$, produce $E[y|X,\\beta]$ for the ***Poisson GLM*** specified above.\n",
        "\n",
        "    ```python\n",
        "    np.random.seed(410)\n",
        "    n,p=100,10\n",
        "    X = stats.norm.rvs(size=(n,p))\n",
        "    X[:,0]=1\n",
        "    X\n",
        "    ```\n",
        "\n",
        "2. (0.5 points) Now simulate $y$ for the ***Poisson GLM*** specified above with seed `np.random.seed(411)`. That is, call `np.random.seed(411)` immediately before sampling $y$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "267c267c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "267c267c",
        "outputId": "e98acaeb-34c3-446f-ff01-8e16277f8145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.45426013e+01 8.77226326e+00 2.25583642e+00 2.04507248e+00\n",
            " 7.97666158e+00 1.20874614e+00 1.19472636e+00 6.36253244e-02\n",
            " 2.20642523e+00 1.61003896e+02 9.34320756e+00 2.36846712e+01\n",
            " 7.79104068e-01 9.94085696e-01 5.29664021e+00 2.96087194e+00\n",
            " 2.93570231e+00 1.00567142e-01 2.91684950e+00 7.74493967e+00\n",
            " 4.74856275e+00 3.81288206e+00 7.23325901e+00 2.88742605e-01\n",
            " 1.10084585e+00 7.61625320e-01 4.25337252e-01 1.06479211e+00\n",
            " 3.62642622e+00 7.85917080e-01 1.94186196e-01 4.94032667e+01\n",
            " 9.01175320e-01 7.24928003e+00 2.03533166e+01 3.04811941e+00\n",
            " 4.17791168e+00 6.50250521e+00 1.35476393e+00 2.04976550e-01\n",
            " 5.91533774e+00 2.84849171e-01 7.56678181e+00 2.56207016e+00\n",
            " 3.51272151e+00 1.97881541e+00 1.42973765e+01 1.36727808e+00\n",
            " 6.13828298e+01 4.67900639e+00 2.12069243e+00 6.18475757e-01\n",
            " 4.45764564e+00 1.09884730e+00 1.05517227e+00 3.29432568e+01\n",
            " 1.01526417e+00 3.61879551e+00 2.43873191e+01 1.72384846e+00\n",
            " 2.44829856e-01 1.27622215e+00 7.87179801e-01 3.46550896e+00\n",
            " 1.85748063e+01 4.61547715e+01 1.43196518e+00 3.73973470e+00\n",
            " 4.26955567e+01 2.02440871e-01 5.36662295e+00 2.94355488e+00\n",
            " 8.85009153e-01 3.83172826e+00 5.82290686e-02 6.69298983e-01\n",
            " 3.93221809e+00 6.57659329e+00 3.46347978e-01 9.10539476e-01\n",
            " 6.67779580e-01 1.54973034e+01 1.64295213e+01 3.95374397e+00\n",
            " 2.92624101e-01 1.48738464e+00 1.20609691e+00 3.64931666e-01\n",
            " 5.31159655e-01 1.18225071e+00 6.72312185e-01 6.11395890e+00\n",
            " 1.09932637e+00 2.48379261e-01 1.99595933e-01 7.42134473e+00\n",
            " 2.43515891e+00 7.10215700e+00 1.26649833e+01 3.15773349e+00]\n"
          ]
        }
      ],
      "source": [
        "# Cell for scratch work\n",
        "np.random.seed(410)\n",
        "n,p=100,10\n",
        "X = stats.norm.rvs(size=(n,p))\n",
        "X[:,0]=1\n",
        "X\n",
        "\n",
        "beta = np.array([(10 - j) / 10 for j in range(p)])\n",
        "\n",
        "E_y = np.exp(X @ beta)\n",
        "print(E_y)\n",
        "# You are welcome to add as many new cells into this notebook as you would like.\n",
        "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
        "\n",
        "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
        "# - all the required functions are still defined and available when called\n",
        "# - no cells requiring variable assignments are deleted.\n",
        "np.random.seed(411)\n",
        "y = np.random.poisson(E_y)\n",
        "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
        "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "6e53965c",
      "metadata": {
        "id": "6e53965c"
      },
      "outputs": [],
      "source": [
        "# Cell for scratch work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "8b0ea9e5",
      "metadata": {
        "id": "8b0ea9e5"
      },
      "outputs": [],
      "source": [
        "# 0.5 points each [format: `np.array` with shape (100, 1)]\n",
        "p1q2 = E_y\n",
        "p1q3 = y # y sampled based on E[y|X,beta] with seed np.random.seed(411)\n",
        "# Assign the appropriate numpy expressions to `p1q2` and `p1q3`\n",
        "\n",
        "# This cell will produce a runtime error until the `p1q2` and `p1q3` variables are assigned values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97608fd2",
      "metadata": {
        "id": "97608fd2"
      },
      "source": [
        "## Problem 1 Question 4 (1 point)\n",
        "\n",
        "4. Define the function `IRLS(X, y, beta_0, m, v, k)` where the default arguments for parameters `m` and `v` are functions returning `E[y|X,beta_t]` and `Var[y|X,beta_t]`, respectively:\n",
        "\n",
        "    - `m = lambda X,beta_t: #E[y|X,beta_t]`\n",
        "    - `v = lambda X,beta_t: #Var[y|X,beta_t]`\n",
        "\n",
        "  and `IRLS` performs `k` ***IRLS*** updates on `beta_0` using `sm.regression.linear_model.WLS`.\n",
        "  \n",
        "Your function will be tested directly for various values of `k` based on `X` and `y` generated above using the initial value `beta_0 = np.zeros((p,1))`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "047437fd",
      "metadata": {
        "id": "047437fd"
      },
      "outputs": [],
      "source": [
        "def IRLS(X, y, beta_0, m = lambda X,beta_t: np.exp(X @ beta_t), v = lambda X,beta_t: np.exp(X @ beta_t), k=1):\n",
        "    '''\n",
        "    X (np.array) with shape (n,p)\n",
        "    y (np.array) with shape (n,1)\n",
        "    beta_0 (np.array) with shape (p,1)\n",
        "    m (function) with paramters (np.arrays) X (n,p) and beta_t (p,1) which returns E[y|X,beta_t]\n",
        "    v (function) with paramters (np.arrays) X (n,p) and beta_t (p,1) which returns Var[y|X,beta_t]\n",
        "    k (int) number of IRLS steps to perform\n",
        "    \n",
        "    returns beta_k (np.array) with shape (p,1) which is the kth IRLS update on beta_0    \n",
        "    '''\n",
        "    # Pass the correct functions to m and v \n",
        "    \n",
        "    beta_t = beta_0.copy()\n",
        "    # <complete>\n",
        "    for _ in range(k):\n",
        "        E_y_t = m(X, beta_t)\n",
        "        Var_y_t = v(X, beta_t)\n",
        "\n",
        "        z = X @ beta_t + (y.reshape(-1, 1) - E_y_t.reshape(-1, 1)) / Var_y_t.reshape(-1, 1)\n",
        "\n",
        "        model = sm.regression.linear_model.WLS(z, X, weights=Var_y_t).fit()\n",
        "\n",
        "        beta_t = model.params.reshape(-1, 1)\n",
        "    return beta_t"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6957359e",
      "metadata": {
        "id": "6957359e"
      },
      "source": [
        "## Problem 1 Question 5-6 (0.5 points)\n",
        "\n",
        "5. (0.25 points) What is the default function assigned for the `m` parameter of the `IRLS` function above?\n",
        "\n",
        "6. (0.25 points) What is the default function assigned for the `v` parameter of the `IRLS` function above?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "fc47ecdd",
      "metadata": {
        "id": "fc47ecdd"
      },
      "outputs": [],
      "source": [
        "# 0.25 points each [format: functions conforming to the IRLS parameters]\n",
        "\n",
        "m = lambda X,beta_t: np.exp(X @ beta_t)\n",
        "p1q5 = m\n",
        "v = lambda X,beta_t: np.exp(X @ beta_t)\n",
        "p1q6 = v\n",
        "# uncomment four lines above once m and v and correctly defined\n",
        "\n",
        "# This cell will produce a runtime error until the `p1q5` and `p1q6` variables are assigned values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628d3051",
      "metadata": {
        "id": "628d3051"
      },
      "source": [
        "## Problem 1 Question 7-8 (1 point)\n",
        "\n",
        "These questions consider the ***IRLS*** algorithm from the more general perspective of ***pseudo (log) likelihoods***.\n",
        "\n",
        "The ***score*** function $S$ and the ***expected Fisher information*** $\\mathcal I$ for a ***pseudo (log) likelihood*** $Q$ (in place of an explicit ***log likelihood***) of a ***generalized linear model*** are\n",
        "\n",
        "\\begin{align*}\n",
        "S_i(\\beta) = \\nabla_\\beta Q(y_i|\\lambda_i=\\phi^{-1}(x_i^T\\beta)) & = {} \\frac{\\partial}{\\lambda_i}Q(y_i|\\lambda_i) \\nabla_\\beta \\lambda_i \\quad \\text{(derivative chain rule)} \\\\\n",
        "& = {} \\frac{\\partial}{\\lambda_i}Q(y_i|\\lambda_i) \\nabla_\\beta \\phi^{-1}(x_i^T\\beta)\\\\\n",
        "& = {} \\frac{\\partial}{\\lambda_i}Q(y_i|\\lambda_i) [\\phi'(\\phi^{-1}(x_i^T\\beta))]^{-1}x_i \\quad \\text{(derivative of inverse rule)}\\\\\n",
        "& \\equiv {} \\frac{y_i-\\lambda_i}{Var(\\lambda_i)} [\\phi'(\\lambda_i)]^{-1}x_i \\quad \\text{(pseudo log likelihood specification)}\\\\\\\\\n",
        "S(\\beta) & = {} \\sum_{i=1}^n \\frac{y_i-\\lambda_i}{Var(\\lambda_i)} [\\phi'(\\lambda_i)]^{-1}x_i = X^T\\underbrace{\\left[\\frac{y-\\lambda}{Var(\\lambda)\\odot \\phi'(\\lambda)}\\right]}_{\\text{element-wise}}\\\\\n",
        "\\mathcal I_i(\\beta) = - E[H Q(y_i|\\lambda_i) ] = - E[J \\nabla_\\beta Q(y_i|\\lambda_i) ] & = {} E[ \\nabla_\\beta Q(y_i|\\lambda_i) \\nabla_\\beta Q(y_i|\\lambda_i)^T ] = E[ S(\\beta) S(\\beta)^T ] \\\\\n",
        "& = {} \\frac{E[(y_i-\\lambda_i)^2]x_ix_i^T}{Var(\\lambda_i)^2[\\phi'(\\lambda_i)]^{2}} = \\frac{x_ix_i^T}{Var(\\lambda_i)[\\phi'(\\lambda_i)]^{2}} \\\\\n",
        "\\mathcal I(\\beta) & = {} \\sum_{i=1}^n \\frac{x_ix_i^T}{Var(\\lambda_i)[\\phi'(\\lambda_i)]^{2}} = X^TD(\\lambda)X \\quad D_{ii}(\\lambda)=\\frac{1}{Var(\\lambda_i)[\\phi'(\\lambda_i)]^{2}} \\quad D_{\\underset{\\neq}{ij}}(\\lambda)=0\n",
        "\\end{align*}\n",
        "\n",
        "***Newton's method*** and ***Fisher scoring*** are thus respectively\n",
        "\n",
        "\\begin{align*}\n",
        "\\beta^{(t+1)} & = {} \\beta^{(t)} - [H Q(y|\\lambda^{(t)})]^{-1} S(\\beta^{(t)})\\\\\n",
        "\\beta^{(t+1)} & = {} \\beta^{(t)} + \\mathcal I(\\beta)^{-1} S(\\beta^{(t)})\\\\\n",
        "& = {} \\beta^{(t)} + (X^TD(\\lambda^{(t)})X)^{-1} S(\\beta^{(t)})\\\\\n",
        "& = {} (X^TD(\\lambda^{(t)})X)^{-1} \\left(X^TD(\\lambda^{(t)})X\\beta^{(t)} + S(\\beta^{(t)}) \\right)\\\\\n",
        "& = {} (X^TD(\\lambda^{(t)})X)^{-1} \\Bigg(X^TD(\\lambda^{(t)})X\\beta^{(t)} + X^TD(\\lambda^{(t)}) \\overbrace{\\left[\\phi'(\\lambda^{(t)}) \\odot (y-\\lambda^{(t)})\\right]}^{\\text{element-wise}} \\Bigg)\\\\\n",
        "& = {} (X^TD(\\lambda^{(t)})X)^{-1} X^TD(\\lambda^{(t)}) \\left(X\\beta^{(t)} + \\left[\\phi'(\\lambda^{(t)}) \\odot (y-\\lambda^{(t)}) \\right] \\right)\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc69d931",
      "metadata": {
        "id": "bc69d931"
      },
      "source": [
        "7. (0.5 points) Recalling that $\\phi'(\\cdot) = (\\cdot)^{-1}$ for ***link function*** $\\phi(\\cdot) = \\ln(\\cdot)$, use the `IRLS` function defined above to perform ***Fisher scoring*** for `X`, `y`,  initial value `beta_0 = np.zeros((p,1))`, and `k=1000` for the ***quasi (log) likelihood*** based on the ***log linear model*** $\\lambda_i = \\exp(x_i^T\\beta)$ with $Var(\\lambda_i) = \\exp(x_i^T\\beta)$.\n",
        "    \n",
        "\n",
        "8. (0.5 points) ***Logistic regression*** with a ***Bernoulli*** distribution\n",
        "\n",
        "    $$f\\left(y_i\\,\\Bigg|\\,\\lambda_i= \\frac{1}{1+\\exp(-x^T_i\\beta)}\\right) = \\lambda_i^{y_i} (1-\\lambda_i)^{1-y_i} = \\left(\\frac{1}{1+\\exp(-x^T_i\\beta)} \\right)^{y_i} \\left(1-\\frac{1}{1+\\exp(-x^T_i\\beta)} \\right)^{1-y_i} $$\n",
        "\n",
        "    has \n",
        "\n",
        "    - $\\lambda_i = E[y_i|x_i,\\beta] = \\frac{1}{1+\\exp(-x^T_i\\beta)}$ and $Var[y_i|x_i,\\beta] = Var(\\lambda_i) = \\left(1-\\frac{1}{1+\\exp(-x^T_i\\beta)}\\right)\\left(\\frac{1}{1+\\exp(-x^T_i\\beta)}\\right)$\n",
        "\n",
        "    - and ***link function*** $\\phi(\\lambda_i) = \\ln\\left(\\frac{\\lambda_i}{1-\\lambda_i}\\right)$ so that $\\phi'(\\lambda_i) = \\frac{1}{\\lambda_i} + \\frac{1}{1-\\lambda_i} = \\frac{1}{\\lambda_i(1-\\lambda_i)}$.\n",
        "\n",
        "    Use the `IRLS` function defined above to perform ***Fisher scoring*** for `X`, `(y>1).asype(int)`, initial value `beta_0 = np.zeros((p,1))`, and `k=1000` for the ***quasi (log) likelihood*** based on $\\lambda_i = \\frac{1}{1+\\exp(-x^T_i\\beta)}$ with $Var(\\lambda_i) = \\lambda_i(1-\\lambda_i)$.\n",
        "\n",
        "***Hint:*** these problem will be most easy to solve if you first simplify the element-wise $D(\\lambda^{(t)})$ and $\\phi'(\\lambda^{(t)}) \\odot (y-\\lambda^{(t)})$ into simpler forms.\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "b1b6cbb7",
      "metadata": {
        "id": "b1b6cbb7"
      },
      "outputs": [],
      "source": [
        "# 0.5 points each [format: `np.array` with shape (p, 1)]\n",
        "beta_0 = np.zeros((p,1))\n",
        "y = y.reshape((-1, 1))\n",
        "\n",
        "p1q7 = IRLS(X, y, beta_0, m=lambda X, beta_t: np.exp(X @ beta_t), v=lambda X, beta_t: np.exp(X @ beta_t), k=1000) # IRLS(X, y, beta_0, m=..., v=..., k=1000)\n",
        "p1q8 = IRLS(X, (y>1).astype(int), beta_0, m=lambda X, beta_t: 1/(1 + np.exp(-X @ beta_t)), v=lambda X, beta_t: (1/(1 + np.exp(-X @ beta_t))) * (1 - (1/(1 + np.exp(-X @ beta_t)))), k=1000)\n",
        "# IRLS(X, (y>1).astype(int), beta_0, m=..., v=..., k=1000)\n",
        "# Assign the appropriate functions for `m` and `v` in order to correctly assign `p1q7` and `p1q8`\n",
        "\n",
        "# This cell will produce a runtime error until the `p1q7` and `p1q8` variables are assigned values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "554e1902",
      "metadata": {
        "id": "554e1902"
      },
      "source": [
        "## Problem 1 Question 9 (0.5 points)\n",
        "\n",
        "9. What is the estimated standard error of the coefficients for question 7?\n",
        "\n",
        "***Hint:*** what is an estimate of the covariance matrix of interest? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "f4884b1f",
      "metadata": {
        "id": "f4884b1f"
      },
      "outputs": [],
      "source": [
        "# Cell for scratch work\n",
        "\n",
        "# You are welcome to add as many new cells into this notebook as you would like.\n",
        "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
        "\n",
        "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
        "# - all the required functions are still defined and available when called\n",
        "# - no cells requiring variable assignments are deleted.\n",
        "\n",
        "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
        "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "1e31975e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e31975e",
        "outputId": "867e350d-3f70-4172-8304-13a69df2f481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99337894]\n",
            " [0.95871935]\n",
            " [0.7368231 ]\n",
            " [0.67169192]\n",
            " [0.52562732]\n",
            " [0.52255555]\n",
            " [0.3746533 ]\n",
            " [0.31115609]\n",
            " [0.17089869]\n",
            " [0.09678262]]\n"
          ]
        }
      ],
      "source": [
        "# Cell for scratch work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "5b061c2d",
      "metadata": {
        "id": "5b061c2d"
      },
      "outputs": [],
      "source": [
        "# 0.5 points [format: `np.array` with shape (p, 1)]\n",
        "\n",
        "p1q9 = 0#\n",
        "\n",
        "# This cell will produce a runtime error until the `p1q9` variable has been assigned a value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "919fe5e3",
      "metadata": {
        "id": "919fe5e3"
      },
      "source": [
        "# Problem 2 (5 points)\n",
        "\n",
        "Complete ***Problem 2*** in the `STA410_CC2_PyMC.ipynb` file.\n",
        "- You will use `X` and `y` generated in ***Problem 1***, so recreate that data in the `STA410_CC2_PyMC.ipynb` file."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Edit Metadata",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}